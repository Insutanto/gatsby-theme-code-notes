---
title: Redis å¤šçº¿ç¨‹å˜è¿(3) ä¹‹ Redis ç½‘ç»œIOçº¿ç¨‹
emoji: ğŸƒ
tags: 
  - redis
  - æºæ¥å¦‚æ­¤
created: 2021-04-20T20:16:50.000Z
modified: 2021-04-25T22:50:50.000Z
---
## ç³»åˆ—æŒ‡åŒ—

Redis å¤šçº¿ç¨‹æºç åˆ†æç³»åˆ—:

[Redis VMçº¿ç¨‹(Redis 1.3.x - Redis 2.4)](https://blog.insutanto.tech/code-notes/2021-04/read-redis-code/vm-thread-in-redis)

[Redis BIOçº¿ç¨‹(Redis 2.4+ å’Œ Redis 4.0+)](https://blog.insutanto.tech/code-notes/2021-04/read-redis-code/bio-thread-in-redis)

[Redis ç½‘ç»œIOçº¿ç¨‹(Redis 6.0+)](https://blog.insutanto.tech/code-notes/2021-04/read-redis-code/network-io-thread-in-redis)


## Redis ç½‘ç»œIOçº¿ç¨‹(Redis 6.0+)

ä»2020å¹´æ­£å¼å‘å¸ƒçš„ Redis 6.0 å¼€å§‹å¼€å§‹ï¼ŒRediså¢åŠ äº†ä¸å®¢æˆ·ç«¯IOè¯»å†™çº¿ç¨‹ï¼Œå‡è½»ä¸»çº¿ç¨‹ä¸å®¢æˆ·ç«¯çš„ç½‘ç»œIOè´Ÿæ‹…ã€‚è€Œå®é™…ä¸Šï¼Œè¿™ä¸ªè®¾æƒ³åœ¨2015å¹´å¼€å‘ lazy free ç‰¹æ€§çš„æ—¶å€™å°±å·²ç»å‡ºç°äº†ã€‚[ã€ŠLazy Redis is better Redisã€‹](http://antirez.com/news/93)#Not just lazy freeing :

> æ—¢ç„¶èšåˆæ•°æ®ç±»å‹çš„å€¼æ˜¯å®Œå…¨ä¸å…±äº«çš„ï¼Œå¹¶ä¸”å®¢æˆ·ç«¯è¾“å‡ºç¼“å†²åŒºä¹Ÿä¸åŒ…å«å…±äº«å¯¹è±¡ï¼Œæœ‰å¾ˆå¤šåœ°æ–¹å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹ã€‚ä¾‹å¦‚ï¼Œæœ€ç»ˆæœ‰å¯èƒ½åœ¨ Redis ä¸­å®ç°çº¿ç¨‹åŒ–I/Oï¼Œä»¥ä¾¿ç”±ä¸åŒçš„çº¿ç¨‹ä¸ºä¸åŒçš„å®¢æˆ·ç«¯æä¾›æœåŠ¡ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬ä»…åœ¨è®¿é—®æ•°æ®åº“æ—¶æ‰å…·æœ‰å…¨å±€é”å®šï¼Œä½†æ˜¯å®¢æˆ·ç«¯è¯»å–/å†™å…¥ç³»ç»Ÿè°ƒç”¨ï¼Œç”šè‡³è§£æå®¢æˆ·ç«¯å‘é€çš„æŒ‡ä»¤æ•°æ®ï¼Œéƒ½å¯ä»¥åœ¨ä¸åŒçš„çº¿ç¨‹ä¸­è¿›è¡Œã€‚è¿™æ˜¯ä¸€ç§ç±»ä¼¼ memcached çš„è®¾è®¡ï¼Œæˆ‘æœŸå¾…å»å®ç°å’Œæµ‹è¯•ã€‚<br/>
è€Œä¸”ï¼Œæœ‰å¯èƒ½å®ç°å¯¹æŸä¸€çº¿ç¨‹ä¸­çš„èšåˆæ•°æ®ç±»å‹æ‰§è¡ŒæŸäº›æ…¢é€Ÿæ“ä½œï¼Œåªä¼šå¯¼è‡´â€œå‡ ä¸ªâ€é”®è¢«â€œé˜»å¡â€ï¼Œè€Œæ‰€æœ‰å…¶ä»–å®¢æˆ·ç«¯éƒ½å¯ä»¥ç»§ç»­å·¥ä½œã€‚è¿™å¯ä»¥é€šè¿‡ä¸æˆ‘ä»¬å½“å‰ä½¿ç”¨é˜»å¡æ“ä½œï¼ˆè¯·å‚é˜…blocking.cï¼‰éå¸¸ç›¸ä¼¼çš„æ–¹å¼æ¥å®ç°ï¼Œæ­¤å¤–è¿˜å¯ä»¥ä½¿ç”¨å“ˆå¸Œè¡¨æ¥å­˜å‚¨å½“å‰æ­£åœ¨ä½¿ç”¨å“ªäº›é”®ä»¥åŠå®ƒä½¿ç”¨çš„å®¢æˆ·ç«¯ã€‚å› æ­¤ï¼Œå¦‚æœå®¢æˆ·è¦æ±‚ä½¿ç”¨SMEMBERSä¹‹ç±»çš„ä¸œè¥¿ï¼Œå°±èƒ½å¤Ÿä»…é”å®šé”®ï¼Œå¤„ç†åˆ›å»ºè¾“å‡ºç¼“å†²åŒºçš„è¯·æ±‚ï¼Œç„¶åå†æ¬¡é‡Šæ”¾é”®ã€‚å¦‚æœæŸä¸ªé”®è¢«é˜»å¡äº†ï¼Œåˆ™å°è¯•è®¿é—®åŒä¸€é”®çš„å®¢æˆ·ç«¯éƒ½å°†è¢«é˜»å¡ã€‚<br/>
æ‰€æœ‰è¿™äº›éƒ½éœ€è¦è¿›è¡Œæ›´å¤§å¹…åº¦çš„å†…éƒ¨ä¿®æ”¹ï¼Œä½†æ˜¯æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ç¦å¿Œè¦å°‘ä¸€äº›ã€‚æˆ‘ä»¬å¯ä»¥ç”¨æ›´å°‘çš„ç¼“å­˜ä¸¢å¤±å’Œæ›´å°‘å†…å­˜å ç”¨çš„èšåˆæ•°æ®ç±»å‹ï¼Œæ¥å¼¥è¡¥å¯¹è±¡å¤åˆ¶çš„æ—¶é—´ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥ç•…æƒ³æ— å…±äº«è®¾è®¡çš„çº¿ç¨‹åŒ– Redis ï¼Œè¿™æ˜¯å”¯ä¸€å¯ä»¥è½»æ¾æˆ˜èƒœæˆ‘ä»¬å•çº¿ç¨‹æ¶æ„çš„è®¾è®¡ã€‚è¿‡å»ï¼Œå¦‚æœä¸ºäº†å®ç°å¹¶å‘è®¿é—®ï¼Œåœ¨æ•°æ®ç»“æ„å’Œå¯¹è±¡ä¸­å¢åŠ ä¸€ç³»åˆ—äº’æ–¥é”ï¼Œå§‹ç»ˆä¼šè¢«è§†ä¸ºä¸€ä¸ªåä¸»æ„ã€‚ä½†ç°åœ¨å¹¸è¿çš„æ˜¯ï¼Œæœ‰æ–¹æ³•å¯ä»¥ä¸¤å…¨å…¶ç¾ã€‚ æˆ‘ä»¬å¯ç°åœ¨ä»¥ä»ç„¶åƒè¿‡å»é‚£æ ·ï¼Œä»ä¸»çº¿ç¨‹ç»§ç»­æ‰§è¡Œæ‰€æœ‰å¿«é€Ÿçš„æ“ä½œã€‚ è€Œè¦åœ¨æ€§èƒ½æ–¹é¢æœ‰æ‰€æ”¶è·ï¼Œéœ€è¦å¢åŠ ä¸€äº›å¤æ‚æ€§ä½œä¸ºä»£ä»·ã€‚<br/>

ä¸Šè¿°æ˜¯ antirez åœ¨ã€ŠLazy Redis is better Redisã€‹çš„ Not just lazy freeing éƒ¨åˆ†æ‰€åˆ†äº«çš„å†…å®¹ï¼Œç†è§£è¿™ä¸ªï¼Œæˆ‘ä»¬å°±èƒ½çŸ¥é“ä¸ºä½• Redis è¦å®ç° IO çº¿ç¨‹åŒ–äº†ï¼š

1. IOå•çº¿ç¨‹æ—¶ï¼ŒæŸäº›é”®çš„é˜»å¡æ“ä½œä¼šé˜»å¡æ•´ä¸ªçº¿ç¨‹ï¼Œè€Œä½¿ç”¨å¤šçº¿ç¨‹ï¼Œå¯ä»¥å®ç°åªæœ‰è®¿é—®ç›¸åŒé”®çš„å®¢æˆ·ç«¯è¢«é˜»å¡ã€‚
2. å»æ‰äº†å…±äº«å¯¹è±¡ï¼Œè®©IOçº¿ç¨‹åŒ–æ›´åŠ ç®€å•ï¼Œä¸å†éœ€è¦å‘æ•°æ®ç»“æ„å’Œå¯¹è±¡ä¸­å¢åŠ ä¸€ç³»åˆ—çš„äº’æ–¥é”æ¥å®ç°å¤šçº¿ç¨‹ï¼Œä»è€Œä¿ç•™äº†Rediså•çº¿ç¨‹çš„â€œä¼ ç»Ÿè‰ºèƒ½â€ã€‚ï¼ˆPSï¼šå»æ‰å…±äº«å¯¹è±¡ï¼Œä¼šå¢åŠ å†…å­˜çš„å¤åˆ¶ï¼Œä½†æ˜¯ä¹Ÿå¯ä»¥å¸¦æ¥å†…å­˜ä¸Šæ›´ç´§å‡‘çš„æ•°æ®ç±»å‹ï¼Œä¹Ÿå› ä¸ºå†…å­˜ä¸Šæ›´åŠ è¿ç»­å¸¦æ¥æ›´å°‘çš„ç¼“å­˜ä¸¢å¤±ã€‚ï¼‰

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä» redis `server.c` ä¸­çš„`main()`å‡½æ•°å¼€å§‹ï¼Œçœ‹çœ‹IOçº¿ç¨‹æ˜¯æ€ä¹ˆè¿è¡Œçš„ã€‚

## IOçº¿ç¨‹çš„åˆ›å»º

![IOçº¿ç¨‹çš„åˆ›å»º](https://mermaid.ink/svg/eyJjb2RlIjoiJSV7aW5pdDogeyd0aGVtZSc6J2Jhc2UnfX0lJVxuZ3JhcGggVEJcbiAgICBzdWJncmFwaCBzZXJ2ZXIuY1xuICAgIFMxKFttYWluXSlcbiAgICBTMltpbml0U2VydmVyXVxuICAgIFMzW0luaXRTZXJ2ZXJMYXN0XVxuICAgIGVuZFxuICAgIHN1YmdyYXBoIG5ldHdvcmtpbmcuY1xuICAgIE4xW2luaXRUaHJlYWRlZElPXVxuICAgIHN1YmdyYXBoIElPVGhyZWFkXG4gICAgSU8xW0lPVGhyZWFkTWFpbl1cbiAgICBJTzJbSU9UaHJlYWRNYWluXVxuICAgIGVuZFxuICAgIGVuZFxuICAgIFMxLS1maXJzdCBjYWxsLS0-UzJcbiAgICBTMS0tdGhlbiBjYWxsLS0-UzNcbiAgICBTMy0tPk4xXG4gICAgTjEtLXB0aHJlYWRfY3JlYXRlLS0-SU8xXG4gICAgTjEtLXB0aHJlYWRfY3JlYXRlLS0-SU8yXG5cbiAgICBcbiIsIm1lcm1haWQiOnt9LCJ1cGRhdGVFZGl0b3IiOmZhbHNlfQ)

é€šè¿‡ `pthread_create` æœç´¢åˆ° `initThreadedIO()` å‡½æ•°ï¼Œç„¶åæ•´ç†ä¸‹IOçº¿ç¨‹çš„åˆ›å»ºè¿‡ç¨‹ï¼š

æ— è®ºæ˜¯å¦å“¨å…µæ¨¡å¼ï¼ŒRediséƒ½ä¼šæ‰§è¡Œ`InitServerLast`ï¼š

```c
int main(int argc, char **argv) {
    struct timeval tv;
    int j;

    server.supervised = redisIsSupervised(server.supervised_mode);
    int background = server.daemonize && !server.supervised;
    if (background) daemonize();

    ......some log......

    readOOMScoreAdj();
    initServer();
    if (background || server.pidfile) createPidFile();
    redisSetProcTitle(argv[0]);
    redisAsciiArt();
    checkTcpBacklogSettings();

    if (!server.sentinel_mode) {
        moduleLoadFromQueue();
        ACLLoadUsersAtStartup();
        InitServerLast();
        loadDataFromDisk();

        ......

    } else {
        InitServerLast();
        sentinelIsRunning();
        ......
    }

    ......

    redisSetCpuAffinity(server.server_cpulist);
    setOOMScoreAdj(-1);

    aeMain(server.el);
    aeDeleteEventLoop(server.el);
    return 0;
}
```

`initServer()`ä¸­ï¼ŒRedisä¼šåˆå§‹åŒ–ç›¸å…³çš„ä»»åŠ¡é˜Ÿåˆ—ï¼Œè€Œåœ¨`InitServerLast`ä¸­ï¼Œæ‰ä¼šåˆå§‹åŒ–ç½‘ç»œIOç›¸å…³çš„çº¿ç¨‹èµ„æºï¼Œå› ä¸ºRedisçš„ç½‘ç»œIOå¤šçº¿ç¨‹æ˜¯å¯ä»¥é…ç½®çš„ã€‚Rediså®ç°äº†ç½‘ç»œIOå¤šçº¿ç¨‹ï¼Œä½†æ˜¯ç½‘ç»œIOçš„é€»è¾‘ï¼Œæ—¢å¯ä»¥åœ¨ThreadedIOçº¿ç¨‹æ‰§è¡Œï¼Œä¹Ÿå¯ä»¥åœ¨ä¸»çº¿ç¨‹æ‰§è¡Œï¼Œç»™ç”¨æˆ·æä¾›äº†é€‰æ‹©ï¼š

```c
void initServer(void) {
    ......
    /* Initialization after setting defaults from the config system. */
    server.aof_state = server.aof_enabled ? AOF_ON : AOF_OFF;
    server.hz = server.config_hz;
    server.pid = getpid();
    server.in_fork_child = CHILD_TYPE_NONE;
    server.main_thread_id = pthread_self();
    server.current_client = NULL; // å½“å‰æ­£åœ¨æ‰§è¡Œå‘½ä»¤çš„å®¢æˆ·ç«¯
    server.errors = raxNew();
    server.fixed_time_expire = 0;
    server.clients = listCreate(); // æ´»è·ƒçš„å®¢æˆ·ç«¯åˆ—è¡¨
    server.clients_index = raxNew(); // æŒ‰ç…§ client_id ç´¢å¼•çš„æ´»è·ƒçš„å®¢æˆ·ç«¯å­—å…¸
    server.clients_to_close = listCreate(); // éœ€è¦å¼‚æ­¥å…³é—­çš„å®¢æˆ·ç«¯åˆ—è¡¨
    server.slaves = listCreate();
    server.monitors = listCreate();
    server.clients_pending_write = listCreate(); // ç­‰å¾…å†™æˆ–è€…å®‰è£…handlerçš„å®¢æˆ·ç«¯åˆ—è¡¨
    server.clients_pending_read = listCreate(); // ç­‰å¾…è¯»socketç¼“å†²åŒºçš„å®¢æˆ·ç«¯åˆ—è¡¨
    server.clients_timeout_table = raxNew();
    server.replication_allowed = 1;
    server.slaveseldb = -1; /* Force to emit the first SELECT command. */
    server.unblocked_clients = listCreate(); // ä¸‹ä¸€ä¸ªå¾ªç¯ä¹‹å‰ï¼Œè¦å–æ¶ˆé˜»å¡çš„å®¢æˆ·ç«¯åˆ—è¡¨
    server.ready_keys = listCreate();
    server.clients_waiting_acks = listCreate();
    server.get_ack_from_slaves = 0;
    server.client_pause_type = 0;
    server.paused_clients = listCreate();
    server.events_processed_while_blocked = 0;
    server.system_memory_size = zmalloc_get_memory_size();
    server.blocked_last_cron = 0;
    server.blocking_op_nesting = 0;
    ......
}
```

åœ¨ `InitServerLast()`ä¸­ ï¼Œé™¤äº† `initThreadedIO` (Redisç½‘ç»œIOçº¿ç¨‹)ï¼Œæˆ‘ä»¬è¿˜èƒ½çœ‹åˆ°`bioInit`(background I/O åˆå§‹åŒ–)ï¼Œä¸¤ä¸ªæ¨¡å—ä½¿ç”¨äº†ä¸åŒçš„èµ„æºï¼š

```c
/* Some steps in server initialization need to be done last (after modules
 * are loaded).
 * Specifically, creation of threads due to a race bug in ld.so, in which
 * Thread Local Storage initialization collides with dlopen call.
 * see: https://sourceware.org/bugzilla/show_bug.cgi?id=19329 */
void InitServerLast() {
    bioInit();
    initThreadedIO();
    set_jemalloc_bg_thread(server.jemalloc_bg_thread);
    server.initial_memory_usage = zmalloc_used_memory();
}
```

æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹çœ‹ Redis æºç çš„ `networking.c` æ–‡ä»¶ï¼š
`io_threads` çº¿ç¨‹æ± ï¼Œ`io_threads_mutex` äº’æ–¥é”ï¼Œ`io_threads_pending` IOçº¿ç¨‹å®¢æˆ·ç«¯ç­‰å¾…æ•°ï¼Œ`io_threads_list` æ¯ä¸ªIOçº¿ç¨‹çš„å®¢æˆ·ç«¯åˆ—è¡¨ã€‚

```c
/* ==========================================================================
 * Threaded I/O
 * ========================================================================== */

#define IO_THREADS_MAX_NUM 128
#define IO_THREADS_OP_READ 0
#define IO_THREADS_OP_WRITE 1

pthread_t io_threads[IO_THREADS_MAX_NUM];
pthread_mutex_t io_threads_mutex[IO_THREADS_MAX_NUM];
redisAtomic unsigned long io_threads_pending[IO_THREADS_MAX_NUM];
int io_threads_op;      /* IO_THREADS_OP_WRITE or IO_THREADS_OP_READ. */

/* This is the list of clients each thread will serve when threaded I/O is
 * used. We spawn io_threads_num-1 threads, since one is the main thread
 * itself. */
list *io_threads_list[IO_THREADS_MAX_NUM];
```

ç„¶åå°±æ˜¯åˆ›å»ºçº¿ç¨‹çš„`initThreadedIO` å‡½æ•°ã€‚åˆå§‹åŒ–çš„æ—¶å€™IOçº¿ç¨‹å¤„äºæœªæ¿€æ´»çŠ¶æ€ï¼Œç­‰å¾…åç»­æ¿€æ´»ï¼Œå¦‚æœ Redis é…ç½®çš„ `io_threads_num` ä¸º 1ï¼Œä»£è¡¨IOä½¿ç”¨ä¸»çº¿ç¨‹å•çº¿ç¨‹å¤„ç†ï¼Œå¦‚æœçº¿ç¨‹æ•°é…ç½®è¶…è¿‡æœ€å¤§å€¼ `IO_THREADS_MAX_NUM` (128) åˆ™å¼‚å¸¸é€€å‡ºï¼Œæœ€åï¼Œ**åˆ›å»ºçš„çº¿ç¨‹éƒ½å°†è¢«é”ä¸Šç›´åˆ°è¢«å”¤é†’**ï¼š

```c
/* Initialize the data structures needed for threaded I/O. */
void initThreadedIO(void) {
    server.io_threads_active = 0; /* We start with threads not active. */

    /* Don't spawn any thread if the user selected a single thread:
     * we'll handle I/O directly from the main thread. */
    if (server.io_threads_num == 1) return;

    if (server.io_threads_num > IO_THREADS_MAX_NUM) {
        serverLog(LL_WARNING,"Fatal: too many I/O threads configured. "
                             "The maximum number is %d.", IO_THREADS_MAX_NUM);
        exit(1);
    }

    /* Spawn and initialize the I/O threads. */
    for (int i = 0; i < server.io_threads_num; i++) {
        /* Things we do for all the threads including the main thread. */
        io_threads_list[i] = listCreate();
        if (i == 0) continue; /* Thread 0 is the main thread. */

        /* Things we do only for the additional threads. */
        pthread_t tid;
        pthread_mutex_init(&io_threads_mutex[i],NULL);
        io_threads_pending[i] = 0;
        pthread_mutex_lock(&io_threads_mutex[i]); /* Thread will be stopped. */
        if (pthread_create(&tid,NULL,IOThreadMain,(void*)(long)i) != 0) {
            serverLog(LL_WARNING,"Fatal: Can't initialize IO thread.");
            exit(1);
        }
        io_threads[i] = tid;
    }
}
```

## IOçº¿ç¨‹çš„å·¥ä½œæµç¨‹

![IOçº¿ç¨‹çš„å·¥ä½œæµç¨‹](https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IFREXG4gICAgc3ViZ3JhcGggc2VydmVyLmNcbiAgICAgICAgUzEoW0V2ZW50TG9vcF0pXG4gICAgICAgIFMyW2JlZm9yZVNsZWVwXVxuICAgIGVuZFxuICAgIHN1YmdyYXBoIG5ldHdvcmtpbmcuY1xuICAgIHN1YmdyYXBoIFJlYWRzVXNpbmdUaHJlYWRzXG4gICAgICAgIFIxW2xpc3RBZGROb2RlVGFpbF1cbiAgICBlbmRcbiAgICBzdWJncmFwaCBXcml0ZXNVc2luZ1RocmVhZHNcbiAgICAgICAgVzNbc3RhcnRUaHJlYWRlZElPXVxuICAgICAgICBXNFtsaXN0QWRkTm9kZVRhaWxdXG4gICAgZW5kXG4gICAgZW5kXG4gICAgUzEtLT5TMlxuICAgIFMyLS1maXJzdCBjYWxsLS0-UmVhZHNVc2luZ1RocmVhZHNcbiAgICBTMi0tdGhlbiBjYWxsLS0-V3JpdGVzVXNpbmdUaHJlYWRzXG4gICAgVzMtLWFkZCBjbGllbnQgdG8gaW9fdGhyZWFkc19saXN0LS0-VzQiLCJtZXJtYWlkIjp7fSwidXBkYXRlRWRpdG9yIjpmYWxzZX0)

Redis åœ¨å¯åŠ¨æ—¶ï¼Œåˆå§‹åŒ–å‡½æ•° `initServer` å°† `beforeSleep` å’Œ `afterSleep` æ³¨å†Œä¸ºäº‹ä»¶å¾ªç¯ä¼‘çœ å‰å’Œä¼‘çœ åçš„`handler` :

```c
void initServer(void) {
......
    server.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR);
......
    /* Register before and after sleep handlers (note this needs to be done
     * before loading persistence since it is used by processEventsWhileBlocked. */
    aeSetBeforeSleepProc(server.el,beforeSleep);
    aeSetAfterSleepProc(server.el,afterSleep);
......
}
```

äº‹ä»¶å¾ªç¯æ‰§è¡Œ `beforeSleep` æ—¶ï¼Œä¼šè°ƒç”¨`handleClientsWithPendingReadsUsingThreads` å’Œ`handleClientsWithPendingWritesUsingThreads`ï¼Œåˆ†åˆ«æ˜¯IOè¯»å†™ä»»åŠ¡çš„åˆ†é…é€»è¾‘ã€‚ç‰¹æ®Šæƒ…å†µä¸‹ï¼Œåœ¨AOFå’ŒRDBæ•°æ®æ¢å¤ï¼ˆä»æ–‡ä»¶è¯»å–æ•°æ®åˆ°å†…å­˜ï¼‰çš„æ—¶å€™ï¼ŒRedisä¼šé€šè¿‡`processEventsWhileBlocked`è°ƒç”¨ `beforeSleep`ï¼Œè¿™ä¸ªæ—¶å€™ï¼Œåªä¼šæ‰§è¡Œ`handleClientsWithPendingReadsUsingThreads` ï¼Œè¿™ä¸ªæ—¶å€™IOå†™æ˜¯**åŒæ­¥**çš„ï¼š

```c
/* This function gets called every time Redis is entering the
 * main loop of the event driven library, that is, before to sleep
 * for ready file descriptors.
 *
 * Note: This function is (currently) called from two functions:
 * 1. aeMain - The main server loop
 * 2. processEventsWhileBlocked - Process clients during RDB/AOF load
 *
 * If it was called from processEventsWhileBlocked we don't want
 * to perform all actions (For example, we don't want to expire
 * keys), but we do need to perform some actions.
 *
 * The most important is freeClientsInAsyncFreeQueue but we also
 * call some other low-risk functions. */
void beforeSleep(struct aeEventLoop *eventLoop) {
......
    /* Just call a subset of vital functions in case we are re-entering
     * the event loop from processEventsWhileBlocked(). Note that in this
     * case we keep track of the number of events we are processing, since
     * processEventsWhileBlocked() wants to stop ASAP if there are no longer
     * events to handle. */
    if (ProcessingEventsWhileBlocked) {
        uint64_t processed = 0;
        processed += handleClientsWithPendingReadsUsingThreads();
        processed += tlsProcessPendingData();
        processed += handleClientsWithPendingWrites();
        processed += freeClientsInAsyncFreeQueue();
        server.events_processed_while_blocked += processed;
        return;
    }

......
    /* We should handle pending reads clients ASAP after event loop. */
    handleClientsWithPendingReadsUsingThreads();

......
    /* Handle writes with pending output buffers. */
    handleClientsWithPendingWritesUsingThreads();

    /* Close clients that need to be closed asynchronous */
    freeClientsInAsyncFreeQueue();

......
    /* Before we are going to sleep, let the threads access the dataset by
     * releasing the GIL. Redis main thread will not touch anything at this
     * time. */
    if (moduleCount()) moduleReleaseGIL();

    /* Do NOT add anything below moduleReleaseGIL !!! */
}
```

åœ¨`handleClientsWithPendingReadsUsingThreads`å‡½æ•°ä¸­ï¼ŒRedisä¼šæ‰§è¡ŒIOè¯»çš„ä»»åŠ¡åˆ†é…é€»è¾‘ï¼Œå½“Redisé…ç½®äº†IOçº¿ç¨‹çš„è¯»å–å’Œè§£æ(`io_threads_do_reads`)ï¼Œå¯è¯»çš„handlerä¼šå°†æ™®é€šçš„å®¢æˆ·ç«¯æ”¾åˆ°å®¢æˆ·ç«¯é˜Ÿåˆ—ä¸­å¤„ç†ï¼Œè€Œä¸æ˜¯åŒæ­¥å¤„ç†ã€‚è¿™ä¸ªå‡½æ•°å°†é˜Ÿåˆ—åˆ†é…ç»™IOçº¿ç¨‹å¤„ç†ï¼Œç´¯ç§¯è¯»å–bufferä¸­çš„æ•°æ®ï¼š

1. IOçº¿ç¨‹åœ¨åˆå§‹åŒ–æ—¶æœªæ¿€æ´»ï¼ŒRedisé…ç½®äº†ç”¨IOçº¿ç¨‹è¯»å–å’Œè§£ææ•°æ®(`io_threads_do_reads`)ï¼Œæ‰ä¼šç»§ç»­æ‰§è¡Œ
2. è¯»å–å¾…å¤„ç†çš„å®¢æˆ·ç«¯åˆ—è¡¨ `clients_pending_read`ï¼Œå°†ä»»åŠ¡æŒ‰ç…§å–æ¨¡å¹³å‡åˆ†é…åˆ°ä¸åŒçº¿ç¨‹çš„ä»»åŠ¡é˜Ÿåˆ—`io_threads_list[target_id]`
3. é€šè¿‡`setIOPendingCount`ç»™å¯¹åº”çš„IOçº¿ç¨‹è®¾ç½®æ¡ä»¶å˜é‡ï¼Œæ¿€æ´»IOçº¿ç¨‹
4. ä¾ç„¶åœ¨ä¸»çº¿ç¨‹å¤„ç†ä¸€äº›å®¢æˆ·ç«¯è¯·æ±‚
5. å¦‚æœå®¢æˆ·ç«¯ç­‰å¾…å†™å…¥ï¼Œå¹¶ä¸”å“åº”çš„bufferè¿˜æœ‰å¾…å†™æ•°æ®ï¼Œæˆ–æœ‰å¾…å‘é€ç»™å®¢æˆ·ç«¯çš„å“åº”å¯¹è±¡ï¼Œåˆ™ç»™å®¢æˆ·ç«¯çš„è¿æ¥å®‰è£…å†™handler

```c
/* When threaded I/O is also enabled for the reading + parsing side, the
 * readable handler will just put normal clients into a queue of clients to
 * process (instead of serving them synchronously). This function runs
 * the queue using the I/O threads, and process them in order to accumulate
 * the reads in the buffers, and also parse the first command available
 * rendering it in the client structures. */
int handleClientsWithPendingReadsUsingThreads(void) {
    // IOçº¿ç¨‹åœ¨åˆå§‹åŒ–æ—¶æœªæ¿€æ´»ï¼ŒRedisé…ç½®äº†ç”¨IOçº¿ç¨‹è¯»å–å’Œè§£ææ•°æ®(io_threads_do_reads)ï¼Œæ‰ä¼šç»§ç»­æ‰§è¡Œ
    if (!server.io_threads_active || !server.io_threads_do_reads) return 0;
    int processed = listLength(server.clients_pending_read);
    if (processed == 0) return 0;

    /* Distribute the clients across N different lists. */
    // è¯»å–å¾…å¤„ç†çš„å®¢æˆ·ç«¯åˆ—è¡¨ clients_pending_readï¼Œ
    // å°†ä»»åŠ¡æŒ‰ç…§å–æ¨¡å¹³å‡åˆ†é…åˆ°ä¸åŒçº¿ç¨‹çš„ä»»åŠ¡é˜Ÿåˆ—io_threads_list[target_id]
    listIter li;
    listNode *ln;
    listRewind(server.clients_pending_read,&li);
    int item_id = 0;
    while((ln = listNext(&li))) {
        client *c = listNodeValue(ln);
        int target_id = item_id % server.io_threads_num;
        listAddNodeTail(io_threads_list[target_id],c);
        item_id++;
    }

    /* Give the start condition to the waiting threads, by setting the
     * start condition atomic var. */
    // é€šè¿‡setIOPendingCountç»™å¯¹åº”çš„IOçº¿ç¨‹è®¾ç½®æ¡ä»¶å˜é‡ï¼Œæ¿€æ´»IOçº¿ç¨‹
    io_threads_op = IO_THREADS_OP_READ;
    for (int j = 1; j < server.io_threads_num; j++) {
        int count = listLength(io_threads_list[j]);
        setIOPendingCount(j, count);
    }

    /* Also use the main thread to process a slice of clients. */
    // ä¾ç„¶åœ¨ä¸»çº¿ç¨‹å¤„ç†ä¸€äº›å®¢æˆ·ç«¯è¯·æ±‚
    listRewind(io_threads_list[0],&li);
    while((ln = listNext(&li))) {
        client *c = listNodeValue(ln);
        readQueryFromClient(c->conn);
    }
    listEmpty(io_threads_list[0]);

    /* Wait for all the other threads to end their work. */
    while(1) {
        unsigned long pending = 0;
        for (int j = 1; j < server.io_threads_num; j++)
            pending += getIOPendingCount(j);
        if (pending == 0) break;
    }

    /* Run the list of clients again to process the new buffers. */
    while(listLength(server.clients_pending_read)) {
        ln = listFirst(server.clients_pending_read);
        client *c = listNodeValue(ln);
        c->flags &= ~CLIENT_PENDING_READ;
        listDelNode(server.clients_pending_read,ln);

        if (processPendingCommandsAndResetClient(c) == C_ERR) {
            /* If the client is no longer valid, we avoid
             * processing the client later. So we just go
             * to the next. */
            continue;
        }

        processInputBuffer(c);

        /* We may have pending replies if a thread readQueryFromClient() produced
         * replies and did not install a write handler (it can't).
         */
        // å¦‚æœå®¢æˆ·ç«¯ç­‰å¾…å†™å…¥ï¼Œ
        // å¹¶ä¸”å“åº”çš„bufferè¿˜æœ‰å¾…å†™æ•°æ®ï¼Œæˆ–æœ‰å¾…å‘é€ç»™å®¢æˆ·ç«¯çš„å“åº”å¯¹è±¡ï¼Œ
        // åˆ™ç»™å®¢æˆ·ç«¯çš„è¿æ¥å®‰è£…å†™handler
        if (!(c->flags & CLIENT_PENDING_WRITE) && clientHasPendingReplies(c))
            clientInstallWriteHandler(c);
    }

    /* Update processed count on server */
    server.stat_io_reads_processed += processed;

    return processed;
}
```

åœ¨ `handleClientsWithPendingWritesUsingThreads` ä¸­ï¼ŒRedisä¼šæ‰§è¡ŒIOçº¿ç¨‹çš„å¯åŠ¨ï¼ŒIOçº¿ç¨‹å†™ä»»åŠ¡çš„åˆ†é…ç­‰é€»è¾‘ï¼š

1. å¦‚æœæ²¡æœ‰å¼€å¯å¤šçº¿ç¨‹ï¼Œæˆ–è€…ç­‰å¾…çš„å®¢æˆ·ç«¯æ•°é‡å°äºçº¿ç¨‹æ•°çš„ä¸¤å€ï¼Œåˆ™æ‰§è¡ŒåŒæ­¥ä»£ç 
2. å¦‚æœ IO çº¿ç¨‹æ²¡æœ‰æ¿€æ´»ï¼Œåˆ™æ¿€æ´»ï¼ˆåœ¨`initThreadedIO`å‡½æ•°åˆ›å»ºçº¿ç¨‹æ—¶å¤„äºæœªæ¿€æ´»çŠ¶æ€ï¼‰
3. å¦‚æœé‡åˆ°éœ€è¦å…³é—­çš„å®¢æˆ·ç«¯(`CLIENT_CLOSE_ASAP`)ï¼Œåˆ™å°†å…¶ä»å¾…å¤„ç†çš„å®¢æˆ·ç«¯åˆ—è¡¨é‡Œåˆ é™¤
4. è¯»å–å¾…å¤„ç†çš„å®¢æˆ·ç«¯åˆ—è¡¨ `clients_pending_write` ï¼Œå°†ä»»åŠ¡æŒ‰ç…§å–æ¨¡å¹³å‡åˆ†é…åˆ°ä¸åŒçº¿ç¨‹çš„ä»»åŠ¡é˜Ÿåˆ—`io_threads_list[target_id]`
5. é€šè¿‡`setIOPendingCount`ç»™å¯¹åº”çš„IOçº¿ç¨‹è®¾ç½®æ¡ä»¶å˜é‡ï¼Œæ¿€æ´»IOçº¿ç¨‹
6. ä¾ç„¶åœ¨ä¸»çº¿ç¨‹å¤„ç†ä¸€äº›å®¢æˆ·ç«¯è¯·æ±‚
7. å¦‚æœå“åº”çš„bufferè¿˜æœ‰å¾…å†™æ•°æ®ï¼Œæˆ–è€…è¿˜æœ‰å¾…å‘é€ç»™å®¢æˆ·ç«¯çš„å“åº”å¯¹è±¡ï¼Œåˆ™ç»™å®¢æˆ·ç«¯çš„è¿æ¥å®‰è£…å†™handler
8. æœ€åè°ƒç”¨`freeClientAsync` å°†å¾…é‡Šæ”¾çš„å®¢æˆ·ç«¯æ”¾å…¥`clients_to_close`é˜Ÿåˆ—ï¼Œç­‰å¾…beforeSleepæ‰§è¡ŒfreeClientsInAsyncFreeQueueæ—¶å®ç°å¼‚æ­¥é‡Šæ”¾å®¢æˆ·ç«¯

```c
int handleClientsWithPendingWritesUsingThreads(void) {
    int processed = listLength(server.clients_pending_write);
    if (processed == 0) return 0; /* Return ASAP if there are no clients. */

    /* If I/O threads are disabled or we have few clients to serve, don't
     * use I/O threads, but the boring synchronous code. */
    // å¦‚æœæ²¡æœ‰å¼€å¯å¤šçº¿ç¨‹ï¼Œæˆ–è€…ç­‰å¾…çš„å®¢æˆ·ç«¯æ•°é‡å°äºçº¿ç¨‹æ•°çš„ä¸¤å€ï¼Œåˆ™æ‰§è¡ŒåŒæ­¥ä»£ç 
    if (server.io_threads_num == 1 || stopThreadedIOIfNeeded()) {
        return handleClientsWithPendingWrites();
    }

    /* Start threads if needed. */
    // å¦‚æœ IO çº¿ç¨‹æ²¡æœ‰æ¿€æ´»ï¼Œåˆ™æ¿€æ´»ï¼ˆåœ¨initThreadedIOå‡½æ•°åˆ›å»ºçº¿ç¨‹æ—¶å¤„äºæœªæ¿€æ´»çŠ¶æ€ï¼‰
    if (!server.io_threads_active) startThreadedIO();

    /* Distribute the clients across N different lists. */
    listIter li;
    listNode *ln;
    listRewind(server.clients_pending_write,&li);
    int item_id = 0;
    while((ln = listNext(&li))) {
        client *c = listNodeValue(ln);
        c->flags &= ~CLIENT_PENDING_WRITE;

        /* Remove clients from the list of pending writes since
         * they are going to be closed ASAP. */
        // å¦‚æœé‡åˆ°éœ€è¦å…³é—­çš„å®¢æˆ·ç«¯(CLIENT_CLOSE_ASAP)ï¼Œåˆ™å°†å…¶ä»å¾…å¤„ç†çš„å®¢æˆ·ç«¯åˆ—è¡¨é‡Œåˆ é™¤
        if (c->flags & CLIENT_CLOSE_ASAP) {
            listDelNode(server.clients_pending_write, ln);
            continue;
        }

        int target_id = item_id % server.io_threads_num;
        listAddNodeTail(io_threads_list[target_id],c);
        item_id++;
    }

    /* Give the start condition to the waiting threads, by setting the
     * start condition atomic var. */
    // é€šè¿‡setIOPendingCountç»™å¯¹åº”çš„IOçº¿ç¨‹è®¾ç½®æ¡ä»¶å˜é‡ï¼Œæ¿€æ´»IOçº¿ç¨‹
    io_threads_op = IO_THREADS_OP_WRITE;
    for (int j = 1; j < server.io_threads_num; j++) {
        int count = listLength(io_threads_list[j]);
        setIOPendingCount(j, count);
    }
    
    /* Also use the main thread to process a slice of clients. */
    // ä¾ç„¶åœ¨ä¸»çº¿ç¨‹å¤„ç†ä¸€äº›å®¢æˆ·ç«¯è¯·æ±‚
    listRewind(io_threads_list[0],&li);
    while((ln = listNext(&li))) {
        client *c = listNodeValue(ln);
        writeToClient(c,0);
    }
    listEmpty(io_threads_list[0]);

    /* Wait for all the other threads to end their work. */
    while(1) {
        unsigned long pending = 0;
        for (int j = 1; j < server.io_threads_num; j++)
            pending += getIOPendingCount(j);
        if (pending == 0) break;
    }

    /* Run the list of clients again to install the write handler where
     * needed. */
    listRewind(server.clients_pending_write,&li);
    while((ln = listNext(&li))) {
        client *c = listNodeValue(ln);

        /* Install the write handler if there are pending writes in some
         * of the clients. */
        // å¦‚æœå“åº”çš„bufferè¿˜æœ‰å¾…å†™æ•°æ®ï¼Œæˆ–è€…è¿˜æœ‰å¾…å‘é€ç»™å®¢æˆ·ç«¯çš„å“åº”å¯¹è±¡ï¼Œ
        // åˆ™ç»™å®¢æˆ·ç«¯çš„è¿æ¥å®‰è£…å†™handler
        if (clientHasPendingReplies(c) &&
                connSetWriteHandler(c->conn, sendReplyToClient) == AE_ERR)
        {
            // å°†å¾…é‡Šæ”¾çš„å®¢æˆ·ç«¯æ”¾å…¥clients_to_closeé˜Ÿåˆ—ï¼Œ
            // ç­‰å¾…beforeSleepæ‰§è¡ŒfreeClientsInAsyncFreeQueueæ—¶å®ç°å¼‚æ­¥é‡Šæ”¾å®¢æˆ·ç«¯
            freeClientAsync(c);
        }
    }
    listEmpty(server.clients_pending_write);

    /* Update processed count on server */
    server.stat_io_writes_processed += processed;

    return processed;
}
```

## IOçº¿ç¨‹çš„ä¸»é€»è¾‘

åœ¨ `IOThreadMain` å‡½æ•°ä¸­ï¼Œæ˜¯ Redis IOçº¿ç¨‹çš„ä¸»é€»è¾‘ã€‚

æˆ‘ä»¬å‘ç°IOçº¿ç¨‹åœ¨åˆ›å»ºåï¼Œä¼šé€šè¿‡`redisSetCpuAffinity`å‡½æ•°å’Œ`server_cpulist`å‚æ•°ï¼Œæ¥è®¾ç½®çº¿ç¨‹çš„CPUçš„äº²å’Œæ€§ï¼Œåˆç†é…ç½®çº¿ç¨‹çš„CPUäº²å’Œæ€§ï¼Œèƒ½å¤Ÿä¸€å®šç¨‹åº¦ä¸Šæå‡æ€§èƒ½ã€‚

ä¹‹åï¼ŒIOçº¿ç¨‹ä¼šæ ¹æ®æ¡ä»¶å˜é‡ `io_threads_pending[id]` åˆ¤æ–­æ˜¯å¦æœ‰ç­‰å¾…çš„IOéœ€è¦å¤„ç†ï¼Œç„¶åä» `io_threads_list[myid]` ä¸­è·å–åˆ†ç»™è‡ªå·±çš„ clientï¼Œå†æ ¹æ® `io_thread_op` æ¥åˆ¤æ–­ï¼Œè¿™ä¸ªæ—¶å€™éœ€è¦æ‰§è¡Œè¯»å†™IOä¸­çš„å“ªä¸€ä¸ªï¼Œ  `readQueryFromClient` è¿˜æ˜¯ `writeToClient` :

```c
void *IOThreadMain(void *myid) {
    /* The ID is the thread number (from 0 to server.iothreads_num-1), and is
     * used by the thread to just manipulate a single sub-array of clients. */
    long id = (unsigned long)myid;
    char thdname[16];

    snprintf(thdname, sizeof(thdname), "io_thd_%ld", id);
    redis_set_thread_title(thdname);
    redisSetCpuAffinity(server.server_cpulist);
    makeThreadKillable();

    while(1) {
        /* Wait for start */
        for (int j = 0; j < 1000000; j++) {
            if (io_threads_pending[id] != 0) break;
        }

        /* Give the main thread a chance to stop this thread. */
        if (io_threads_pending[id] == 0) {
            pthread_mutex_lock(&io_threads_mutex[id]);
            pthread_mutex_unlock(&io_threads_mutex[id]);
            continue;
        }

        serverAssert(io_threads_pending[id] != 0);

        if (tio_debug) printf("[%ld] %d to handle\n", id, (int)listLength(io_threads_list[id]));

        /* Process: note that the main thread will never touch our list
         * before we drop the pending count to 0. */
        listIter li;
        listNode *ln;
        listRewind(io_threads_list[id],&li);
        while((ln = listNext(&li))) {
            client *c = listNodeValue(ln);
            if (io_threads_op == IO_THREADS_OP_WRITE) {
                writeToClient(c,0);
            } else if (io_threads_op == IO_THREADS_OP_READ) {
                readQueryFromClient(c->conn);
            } else {
                serverPanic("io_threads_op value is unknown");
            }
        }
        listEmpty(io_threads_list[id]);
        io_threads_pending[id] = 0;

        if (tio_debug) printf("[%ld] Done\n", id);
    }
}
```

## æ€»ç»“

ä»Redis VMå¼€å§‹ï¼Œåˆ°Redis BIOï¼Œå†åˆ°æœ€åçš„IOå¤šçº¿ç¨‹ï¼Œæˆ‘ä»¬èƒ½çœ‹åˆ° Redis æ­£åœ¨é€æ¸çš„å‘çº¿ç¨‹åŒ–çš„æ–¹å‘å‘å±•ã€‚ç‰¹åˆ«æ˜¯åœ¨å®ç°Lazy Freeä¹‹å(Redis BIO)ï¼Œantirezä¼¼ä¹å°åˆ°äº†å¤šçº¿ç¨‹çš„å¥½å¤„ï¼Œåœ¨ä¿è¯dbæ“ä½œå•çº¿ç¨‹çš„æƒ…å†µä¸‹ï¼Œè®©Rediså‘æŒ¥CPUä¸€éƒ¨åˆ†å¤šæ ¸å¤šçº¿ç¨‹çš„å®åŠ›ã€‚æˆ‘ä»¬ä¸éš¾å‘ç°ï¼ŒRedis çš„å¤šçº¿ç¨‹ä¸è¿‡æ˜¯é¡ºåŠ¿è€Œä¸ºç½¢äº†ï¼Œå¦‚æœå•çº¿ç¨‹æ²¡æœ‰ç“¶é¢ˆï¼Œå°±ä¸ä¼šäº§ç”Ÿä½¿ç”¨å¤šçº¿ç¨‹çš„Redisã€‚å†ç»“åˆç°çŠ¶æ¥çœ‹ï¼Œæ¯•ç«Ÿæ—¶ä»£å˜äº†ï¼Œä»å¤šå¹´å‰çš„å•æ ¸æœåŠ¡å™¨ï¼Œåˆ°åæ¥çš„åŒæ ¸ï¼Œå››æ ¸æœåŠ¡å™¨ï¼Œå†åˆ°ç°åœ¨åŠ¨è¾„å…«æ ¸ï¼Œåå…­æ ¸çš„æœåŠ¡å™¨ï¼š
å•çº¿ç¨‹æ¨¡å‹å›ºç„¶ç®€å•ï¼Œä»£ç æ¸…æ™°ï¼Œä½†æ˜¯åœ¨æ‘©å°”å®šå¾‹å¤±æ•ˆï¼Œå¤šæ ¸å¤šçº¿ç¨‹çš„æ—¶ä»£æ´ªæµä¸‹ï¼Œæœ‰è°èƒ½å¤Ÿæ‹’ç»å¤šçº¿ç¨‹çš„å¥½å¤„å‘¢ï¼Ÿ